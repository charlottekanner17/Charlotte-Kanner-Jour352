<!doctype html>
<html lang="en">
     
    <head>
                
        <meta charset="utf-8" />
           
        <meta
            name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <link rel="preconnect" href="https://fonts.googleapis.com" />
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
        <link
            href="https://fonts.googleapis.com/css2?family=Newsreader:ital,opsz,wght@0,6..72,200..800;1,6..72,200..800&display=swap"
            rel="stylesheet" />
        <link rel="preconnect" href="https://fonts.googleapis.com" />
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
        <link
            href="https://fonts.googleapis.com/css2?family=Newsreader:ital,opsz,wght@0,6..72,200..800;1,6..72,200..800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"
            rel="stylesheet" />
        <!-- Bootstrap CSS -->
           
        <link
            href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"
            rel="stylesheet"
            integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH"
            crossorigin="anonymous" />

        <link href="style.css" rel="stylesheet" />
            
    </head>

    <body>
        <div class="container-fluid" id="topper"></div>
        <div class="row"></div>
        <div class="col"></div>
        <h1>
            <video width="320" height="240" autoplay>
                <source src="movie.mp4" type="video/mp4" />
                <source src="movie.ogg" type="video/ogg" />
                Your browser does not support the video tag.
            </video>
            <div
                style="
                    position: relative;
                    width: 100%;
                    height: 0;
                    padding-top: 56.25%;
                    padding-bottom: 0;
                    box-shadow: 0 2px 8px 0 rgba(63, 69, 81, 0.16);
                    margin-top: 1.6em;
                    margin-bottom: 0.9em;
                    overflow: hidden;
                    border-radius: 8px;
                    will-change: transform;
                ">
                <iframe
                    loading="lazy"
                    style="
                        position: absolute;
                        width: 100%;
                        height: 100%;
                        top: 0;
                        left: 0;
                        border: none;
                        padding: 0;
                        margin: 0;
                    "
                    src="https:&#x2F;&#x2F;www.canva.com&#x2F;design&#x2F;DAGE9CjzzaA&#x2F;AxYJmXX0gIOVzAjeUNZAMw&#x2F;watch?embed"
                    allowfullscreen="allowfullscreen"
                    allow="fullscreen">
                </iframe>
            
                
            </div>
            <a
                href="https:&#x2F;&#x2F;www.canva.com&#x2F;design&#x2F;DAGE9CjzzaA&#x2F;AxYJmXX0gIOVzAjeUNZAMw&#x2F;watch?utm_content=DAGE9CjzzaA&amp;utm_campaign=designshare&amp;utm_medium=embeds&amp;utm_source=link"
                target="_blank"
                rel="noopener">
            </a>
            <figure>
          
                <figcaption> 
                  (Source: Telegram. Note: The text exchanges displayed in this story have been edited for length. Illustration by Charlotte Kanner; Canva.)</figcaption>
                      </figure>
            On popular online platforms, predatory groups coerce children into
            self-harm
            <p class="titlesub"> Vulnerable teens are blackmailed into degrading and violent acts
                by abusers who then boast about it
            </p>
            <p class="author"> By: Charlotte Kanner</p>
            <p class="date"> March 11, 2024</p>
            <br>
    
        </h1>

        <div class="container-fluid" id="content"></div>
        <div class="row"></div>
        <div class="col">
            <p>
                The person in the online chat introduced himself as “Brad.”
                Using flattery and guile, he persuaded the 14-year-old girl to
                send a nude photo. It instantly became leverage.
            </p>
            <p>
                Over the following two weeks in April 2021, he and other online
                predators threatened to send the image to the girl’s classmates
                in Oklahoma unless she live-streamed degrading and violent acts,
                the girl’s mother told The Washington Post.
            </p>
             <div class="gallery">
                <a target="_blank" href="img_5terre.jpg">
                    <img
                        src="Screen Shot 2024-05-13 at 2.03.19 AM.png"
                        alt="Cinque Terre"
                        width="600"
                        height="400" />
                </a>
                <a class="link" href="https://www.missingkids.org/home" target="_blank">Missing Kids</a>
            </div>

            <div class="gallery">
                <a target="_blank" href="img_forest.jpg">
                    <img
                        src="Screen Shot 2024-05-13 at 2.03.26 AM.png"
                        alt="Forest"
                        width="600"
                        height="400" />
                </a>
                 <a class="link" href="https://www.ic3.gov/Home/ComplaintChoice" target="_blank">Complaint Choice</a>
            </div>
            <p>
                They coerced her into carving their screen names deep into her
                thigh, drinking from a toilet bowl and beheading a pet hamster —
                all as they watched in a video chatroom on the social media
                platform Discord.
            </p>
            <p>
                The pressure escalated until she faced one final demand: to kill
                herself on camera.
            </p>
            <p>
                “You just don’t realize how quickly it can happen,” said the
                mother, who intervened before her daughter could act on the
                final demand. The mother agreed to talk about the experience to
                warn other parents but did so on the condition of anonymity out
                of concern for her daughter’s safety.
            </p>
            <p>
                The abusers were part of an emerging international network of
                online groups that have targeted thousands of children with a
                sadistic form of social media terror that authorities and
                technology companies have struggled to control, according to an
                examination by The Washington Post, Wired Magazine, Der Spiegel
                in Germany and Recorder in Romania.
            </p>
            <p>
                The perpetrators — identified by authorities as boys and men as
                old as mid-40s — seek out children with mental health issues and
                blackmail them into hurting themselves on camera, the
                examination found. They belong to a set of evolving online
                groups, some of which have thousands of members, that often
                splinter and take on new names but have overlapping membership
                and use the same tactics.
            </p>
    
            <p>
                Unlike many “sextortion” schemes that seek money or increasingly
                graphic images, these perpetrators are chasing notoriety in a
                community that glorifies cruelty, victims and law enforcement
                officials say. The FBI issued a public warning in September
                identifying eight such groups that target minors between the
                ages of 8 and 17, seeking to harm them for the members’ “own
                entertainment or their own sense of fame.”
            </p>
            <figure>
                <img
                    src="Screen Shot 2024-05-11 at 5.56.39 PM.png"
                    alt="Oklahoma women whose daughter was targeted by predators "
                    id="picture" />
                <figcaption>
                    An Oklahoma woman whose daughter was targeted by predators
                    on Discord agreed to be photographed for this report on the
                    condition that her identity not be revealed to protect the
                    safety of her family. (Nick Oxford for The Washington Post)
                </figcaption>
            </figure>
            <p>
                The group that targeted the Oklahoma girl and others interviewed
                for this report is called “764,” named after the partial Zip
                code of the teenager who created it in 2021. Its activities fit
                the definition of domestic terrorism, the FBI recently argued in
                court.
            </p>
            <p>
                “I had the feeling that they really loved me, that they cared
                about me,” said an 18-year-old woman from Canada who described
                being “brainwashed” and then victimized by the group in 2021.
                “The more content they had of you, the more that they used it,
                the more that they started to hate you.”
            </p>
            <p>
                While lawmakers, regulators and social media critics have long
                scrutinized how Facebook and Instagram can harm children, this
                new network thrives on Discord and the messaging app Telegram —
                platforms that the group 764 has used as “vessels to desensitize
                vulnerable populations” so they might be manipulated, a federal
                prosecutor said in court recently.
            </p>
          
            <p>
                Discord, a hub for gamers, is one of the most popular social
                media platforms among teens and is growing fast. The platform
                allows anonymous users to control and moderate large swaths of
                its private meeting rooms with little oversight.
            </p>
            <img
                src="1284183.png" alt="In the fourth quarter of 2023, Discord
                users reported over six million pieces of platform manipulation.
                Cases of reported harassment and bullying came in second, with
                over two million reports taken action against. Additionally,
                Discord took action against approximately 895 thousand reports
                of exploitative and unsolicited content during the examined
                period. (Laura Ceci for Statistica)" />
            <figcaption>
                In the fourth quarter of 2023, Discord users reported over six
                million pieces of platform manipulation. Cases of reported
                harassment and bullying came in second, with over two million
                reports taken action against. Additionally, Discord took action
                against approximately 895 thousand reports of exploitative and
                unsolicited content during the examined period. (Laura Ceci for
                Statistica)"
            </figcaption>
            <p>
                Telegram — an app that includes group chats and has more than
                800 million monthly users — allows for fully encrypted
                communication, a feature that protects privacy but makes
                moderation more challenging. Telegram delegates most moderation
                to leaders of groups on the platform, intervening in some
                instances when posts violate its policies.
            </p>
            <p>
                On Telegram, members of these groups post child pornography,
                videos of corpse desecration and images of the cuts they have
                made children inflict on themselves, according to victims and an
                examination of messages. In chat groups with as many as 5,000
                members, they brag about their abusive acts and goad each other
                on. They share tips on where to find girls with eating disorders
                and other vulnerabilities congregating online, and on how to
                manipulate them.
            </p>
            <p>
                In a group chat on Telegram this past April, one such member
                wrote that he had obtained an 18-minute video of a minor
                engaging in sexual acts. He wrote that she was “the 14th girl
                this month.”
            </p>
            <p>
                The platforms say deterring these groups is an urgent priority.
                But after creating the spaces that predators from around the
                globe use to connect with one another and find vulnerable
                children, even removing thousands of accounts each month has
                proved insufficient. The targeted users start new accounts and
                swiftly reconvene, according to interviews with victims.
            </p>
            <p>
                In a statement, Telegram did not respond to detailed questions
                about this network but said it removes “millions” of pieces of
                harmful content each day through “proactive monitoring of public
                parts of the platform and user reports.”
            </p>
            <p>
                “Child abuse and calls to violence are explicitly forbidden by
                Telegram’s terms of service,” said Remi Vaughn, a Telegram
                spokesperson. “Telegram has moderated harmful content on our
                platform since its creation.”
            </p>
            <p>
                After reporters sought comment, Telegram shut down dozens of
                groups the consortium identified as communication hubs for the
                network.
            </p>
            <p>
                Discord has filed “many hundreds” of reports about 764 with law
                enforcement authorities, according to a company spokeswoman,
                speaking on the condition of anonymity for fear of retaliation
                from 764-affiliated groups. The company removed 34,000 user
                accounts associated with the group last year, many of them
                assumed to be repeat offenders, she said.
            </p>
            <br>
            <hr>
            <p class="pullquote">
                “It’s their responsibility to provide a safe space for
                everyone.” — Mother of a 764 victim in Oklahoma, referring to
                Discord
            </p> 
            <hr>
            <br>           
            <p>
                “The actions of 764 are appalling and have no place on Discord
                or in society,” the company said in a statement. “Since 2021,
                when Discord first became aware of 764, disrupting the group and
                its sadistic activity has been among our Safety team’s highest
                priorities. Discord has specialized groups who focus on
                combating this decentralized network of internet users, and 764
                has and continues to be a target of their daily work.”
            </p>
            <p>
                The company uses artificial intelligence to detect predatory
                behavior and scans for abusive text and known sexually explicit
                images of children in the platform’s public spaces, the
                spokeswoman said. It shuts down problem accounts and meeting
                spaces and sometimes bans users with a particular IP address,
                email or phone number, though the spokeswoman acknowledged that
                sophisticated users can sometimes evade these measures.
            </p>
            <p>
                The Post and its media partners shared reporting for this
                examination, including court and police records from multiple
                countries, and interviews with researchers, law enforcement
                officials and seven victims or their families — all of whom
                spoke on the condition of anonymity to protect their safety — in
                North America and Europe. The media consortium also collected
                and analyzed 3 million Telegram messages. Each news organization
                wrote its own story.
            </p>
            <p>
                The Oklahoma girl’s mother said she holds Discord responsible
                for her daughter’s abuse, detailed in videos and police records.
            </p>
            <p>
                “Discord has provided a safe space for evil people,” the mother
                said. “It’s their responsibility to provide a safe space for
                everyone.”
            </p>
            <p class="subheading"> A cult that prizes sadistic acts</p>
            <p>
                The founder of 764 was a 16-year-old boy in Texas who used
                variations of the screen names “Felix” or “Brad” while running
                the group’s online operations from his mother’s home. Bradley
                Cadenhead soon developed a following online as the leader of a
                self-described cult that prized sadistic acts, according to
                court records that describe both his online and real-world
                lives.
            </p>
            <p>
                Cadenhead became fascinated with violent imagery at age 10, the
                records say. Three years later, he was sent to a juvenile
                detention center after allegedly threatening to shoot up his
                school.
            </p>
            <p>
                He created the first 764 Discord server in January 2021,
                according to the company spokeswoman. Discord servers are
                meeting spaces where members gather to communicate with each
                other by text, voice and video. The person who creates a server
                controls who is admitted to it and who moderates its content.
            </p>
            <p>
                The group’s name refers to the first three numbers in the Zip
                code of Cadenhead’s hometown, Stephenville, about 100 miles
                southwest of Dallas, said Stephenville Police Capt. Jeremy
                Lanier.
            </p>
            <p>
                Court and police records show that Discord struggled to keep
                Cadenhead off its platform.
            </p>
            <p>
                Starting in November 2020, the company spokeswoman said, Discord
                noticed that child sexual abuse material was being uploaded from
                IP addresses — a set of numbers that identify a device used to
                connect to the internet — that investigators later traced back
                to Cadenhead. The company sent authorities reports about illegal
                images on 58 different accounts operated by Cadenhead, well into
                2021, the spokeswoman said.
            </p>
            <p>
                Lanier told The Post that Cadenhead was uploading child
                pornography on Discord as late as July 2021, several months
                after the Oklahoma girl was groomed and abused there.
            </p>
            <p>
                The Discord spokeswoman said that each time one of Cadenhead’s
                accounts was flagged, it was shut down and banned. She
                acknowledged that the company banned only some of the IP
                addresses used by Cadenhead, saying that it used such bans only
                when they were deemed tactically appropriate. She said
                sophisticated predators often have 50 to 100 accounts, some
                stolen or purchased, to evade enforcement actions.
            </p>
            <p>
                The reports from Discord prompted the investigation that led to
                his arrest on child pornography charges in July 2021. Speaking
                later to a juvenile probation officer, Cadenhead said that his
                server attracted as many as 400 members who routinely posted
                shocking images, including videos of torture and child
                pornography. It was also “quite common” for members to groom
                victims and extort them by threatening to distribute
                compromising images, Cadenhead told the officer. Sometimes their
                motivation was money, and other times they did it “just for
                power,” the officer wrote in a report to the court after
                Cadenhead pleaded guilty.
            </p>
            <p>
                Cadenhead, now 18 and serving an 80-year prison sentence for
                possession with intent to promote child pornography, did not
                respond to a letter requesting an interview. His parents did not
                return messages. Chris Perri, a lawyer for Cadenhead, said he
                may challenge the sentence based on “potential mental health
                issues.”
            </p>
            <p>
                Lanier said that in six years of investigating child pornography
                cases he had “never seen anything as dark as this. Not even
                close.”
            </p>
            <p class="subheading"> ‘What did they want you to do’</p>
            <figure>
                <img
                    src="Screen Shot 2024-05-12 at 5.16.41 PM.png"
                    alt="Oklahoma women whose daughter was targeted by predators "
                    id="picture" />
                <figcaption>
                    A woman whose daughter was targeted by online predators
                    through Discord shows messages she sent to her child. (Nick
                    Oxford for The Washington Post)
                </figcaption>
            </figure>
            <p>
                The Oklahoma teenager’s experience with 764 started innocuously,
                her mother said in an interview. The girl downloaded the Discord
                app on her phone because her middle school art teacher
                encouraged students to use it to share their work. A fan of
                horror stories, she soon began searching for gory content.
            </p>
            <p>
                She landed in a chatroom where she met “Brad,” who flattered her
                and invited her to the 764 server. The 14-year-old was typical
                of children victimized by these groups: She had a history of
                mental illness, having been hospitalized for depression the
                previous November, her mother said.
            </p>
            <p>
                “He pretended to like her as a girlfriend,” the mother said.
                “She sent him videos or pictures. And then the manipulation and
                control started. ”
            </p>
            <p>
                For more than two weeks, the girl complied with the demands of a
                handful of abusers in the 764 server, live-streaming some videos
                from inside her bedroom closet while her mother was in the
                house, according to her mother. They told the girl that if she
                didn’t comply they would send explicit photos of her to her
                social media followers, classmates and school principal. They
                threatened to hurt her younger brother.
            </p>
            <p>
                The Post reviewed a video of the girl that was still circulating
                on Telegram late last year, a recording of a live stream on the
                764 Discord server. The girl holds the family’s hamster in one
                hand and a razor blade in the other as three males berate her.
                “Bite the head off, or I’ll f--- up your life,” a male with the
                screen name “Felix” yells, as she sobs. “Stop crying,” says
                another male.
            </p>
        <br>
            <hr>
            <p class="pullquote">
                “People are not understanding the severity, the speed at which
                their children can become victimized.” — Abbigail Beccaccio,
                chief of the FBI’s Child Exploitation Operational Unit
            </p>
            <hr>
        <br>
            <p>
                The girl’s mother said in an interview that “Brad” coerced her
                daughter into killing the hamster. The victim from Canada said
                she was in the Discord server at the time and confirmed that the
                764 leader pressured the girl into mutilating the animal as
                dozens of people watched online.
            </p>
            <p>
                The girl’s mother found out about the extortion later that same
                night in April 2021.
            </p>
            <p>
                She heard the muffled sound of her daughter’s voice through the
                bathroom door, talking to someone as she bathed. She waited by
                the door until her daughter opened it. On her daughter’s torso
                were self-inflicted cuts the abusers had told her to make while
                she was in the bathtub, the mother said.
            </p>
            <p>
                The girl told her mother that a cult was extorting her and that
                she had been instructed to take her own life the following day.
            </p>
            <p>
                “I believe she was going to kill herself,” the mother said. “If
                I had not been at that bathroom door, I have no doubt I would
                have lost my daughter.”
            </p>
            <p>The mother struggled to understand the depravity.</p>
            <p>
                “What did they want you to do?” she asked later, in a text
                message to her daughter.
            </p>
            <p>
                “Cut their names,” her daughter answered. “Cut until the bath
                was red. Lick a knife with blood.”
            </p>
            <p>
                The mother shut off the teen’s contact with the group and spoke
                with local police, but harassment followed, records show. The
                principal at the girl’s middle school received multiple
                anonymous calls saying the girl had strangled cats and harmed
                herself, according to a police report obtained by The Post. The
                group also “swatted” the family, falsely reporting an emergency
                at the house that prompted police to respond, the mother said.
            </p>
            <p>
                The investigation by police in the Oklahoma town never
                identified the girl’s online abusers, police records show, with
                a detective noting a handful of Discord screen names of the
                suspects, including “Brad.”
            </p>
            <p class="subheading">Moderators struggle as the network grows</p>
            <p>
                In the nearly three years since, the network has grown and
                reports of abuse have risen, posing a challenge to social media
                platforms.
            </p>
            <p>
                Abbigail Beccaccio, chief of the FBI’s Child Exploitation
                Operational Unit, estimated that thousands of children have been
                targeted by the online groups using these tactics, although she
                declined to discuss any groups by name.
            </p>
            <p>
                “People are not understanding the severity, the speed at which
                their children can become victimized,” she said. “These are
                offenders that have the ability to change your child’s life in a
                matter of minutes.”
            </p>
            <p>
                A nonprofit that directs reports of abuse against children from
                social media companies to law enforcement said it saw a sharp
                increase in this type of exploitation last year. Fallon McNulty,
                director of the CyberTipline at the National Center for Missing
                and Exploited Children, said the center received hundreds of
                reports of minors extorted into hurting themselves last year and
                continues to receive dozens each month.
            </p>
            <p>
                These online groups, she said, are responsible for “some of the
                most egregious online enticement reports that we’re seeing in
                terms of what these children are being coerced to do.”
            </p>
            <p>
                A 13-year-old girl in England said she witnessed a young man
                hang himself on the 764 server last January. The 18-year-old
                Canadian said she watched a male shoot himself in the head on a
                Discord live stream.
            </p>
            <p>
                “They wanted you in the groups and they were going to ridicule
                you and drive you to suicide,” the Canadian said.
            </p>
            <p>
                The Discord spokeswoman said the company is assisting law
                enforcement in an investigation of the incident described by the
                Canadian woman. The spokeswoman declined to comment on the
                incident described by the girl in England or say how many
                suicides on the platform have been linked to 764.
            </p>
            <p>
                Although the FBI could not say how many deaths are attributable
                to this network, the agency said at least 20 children died by
                suicide in the United States as a result of being extorted with
                nude images between October 2021 and March 2023.
            </p>
            <p>
                The Discord spokeswoman said the company met with the FBI in
                2021 after learning about the existence of 764 on its platform.
                She declined to provide details about the meeting but said the
                FBI was not aware of the group at the time.
            </p>
            <p>
                The FBI’s first public mention of 764 was the warning it issued
                in September. The bureau declined to comment on any steps it
                took to investigate the group after the 2021 meeting.
            </p>
            <p>
                Discord said it has worked to rid the platform of the group’s
                members, dedicating senior officials on its safety team
                specifically to targeting the group.
            </p>
            <p>
                “We proactively detect, remove, and ban related servers,
                accounts, and users,” the company said in a statement. “We will
                continue working relentlessly to keep this group off our
                platform and to assist in the continued capture and prosecution
                of these violent actors.”
            </p>
            <p>
                Victims said in interviews that when Discord’s moderators took
                down servers and banned accounts, users would simply create new
                ones.
            </p>
            <p>
                “The 764 Discord groups [would] keep getting taken down. They
                [would] bring them back up, and then they take it down and they
                bring it back up. It’s a cycle that keeps repeating,” said the
                18-year-old from Canada.
            </p>
            <p>
                Even though she was a victim, she said her Discord accounts were
                regularly banned because she was in servers that contained
                violent imagery. She estimated that she created 50 to 100
                different Discord accounts with new identifying information each
                time. “I kept getting deleted, and I just kept making more new
                emails, new phone numbers, all of the above,” she said.
            </p>
            <p>
                A killing in Romania in 2022 illustrates users’ ability to get
                around bans. A 764 member who went by the screen names “tobbz”
                and “voices” fatally stabbed an elderly woman on a Discord live
                stream that April. Months earlier, Discord had shut down one of
                his accounts and reported him to authorities, the spokeswoman
                said, but he managed to remain on the platform.
            </p>
            <p>
                The attacker, a German teenager whose name has not been released
                by authorities because he was a minor, was convicted of murder
                and sentenced to 14 years in prison. “I committed the crime just
                to provide content within the group,” he told Romanian
                investigators, referring to a 764 affiliate.
            </p>
            <p>
                The Discord groups often have parallel channels on Telegram,
                where members exchange tips on how to avoid Discord bans and
                groom victims. They boast about their exploitation, posting
                photos of victims’ with their screen names cut into their
                bodies.
            </p>
            <p>
                They also share screenshots of their exchanges with victims,
                such as one posted to a Telegram channel in January.
            </p>
            <img
                    src="Screen Shot 2024-05-13 at 1.13.39 AM.png"
                    alt="Text messages between predator and child"
                    id="picture" />
            <p>
                A how-to guide circulated on Telegram offers tips on how to
                groom girls who are “emotionally weak/vulnerable.”
            </p>
            <p>
                “Gain her trust, make her feel comfortable doing anything for
                you, make her want to cut for you by getting to her emotions and
                making it seem like youre the only person she could ever need in
                her life,” it advises.
            </p>
            <p>
                Another guide advises targeting girls who have eating disorders
                or bipolar disorder.
            </p>
            <p>
                The Post and its partners also found several video recordings on
                Telegram of victims being abused on Discord, including the
                Oklahoma girl and others who had carved usernames and group
                names into their bodies. Some users on Telegram noted that
                Discord had stepped up its enforcement in the past year and said
                that it was more difficult to stay on the platform.
            </p>
            <p>
                There were also comments about recruiting victims on Roblox, a
                gaming platform popular with young children.
            </p>
            <p>
                “I groomed him on Roblox,” a user wrote in May 2023. “Told him
                to mic up. Then started grooming him”
            </p>
            <p>
                A Roblox spokesperson said the platform is aware of the groups’
                activities.
            </p>
            <p>
                “Fortunately, these crime rings and organizations represent a
                small number of users, but they evolve their tactics in an
                attempt to evade our detection by relying on coded messages and
                avoid violation of Roblox policies. Our sophisticated systems
                and teams are extremely vigilant in looking for imagery,
                language or behavior associated with them.”
            </p>
            <p>
                Experts said social media companies have little financial
                incentive to eliminate child abuse under the current law, which
                shields them from liability for content posted on their
                platforms.
            </p>
            <p>
                “When you create liability for these companies, they have to
                absorb it,” said Hany Farid, a computer science professor at the
                University of California at Berkeley. “When they absorb it, they
                make different decisions because the economics change.”
            </p>
            <p class="subheading">‘Tired of living in fear’</p>
            <p>
                In recent months, there have been signs that the FBI is ramping
                up its investigations into the network of related groups,
                starting with the public warning in September.
            </p>
            <p>
                Between October and January, federal prosecutors in court
                documents identified three men facing child pornography charges
                as members or associates of 764.
            </p>
            <p>
                Federal authorities have also begun examining 764’s imprisoned
                founder. In November, the FBI asked Stephenville police to share
                the information they had collected during their investigation of
                Cadenhead two years earlier, according to Lanier, the police
                captain. The following month, the mother of the girl in Oklahoma
                said, FBI agents contacted her and asked her to recount the
                details of the abuse. She said she was not told why the FBI was
                interested in the case. The FBI declined to comment.
            </p>
            <p>
                The criminal case that led to Cadenhead’s imprisonment did not
                include charges for abusing the Oklahoma girl, and the girl’s
                mother said she was not notified of his arrest.
            </p>
            <p>
                For years, not knowing the identity of her daughter’s tormentors
                has left the mother fearful of what they might do next. She was
                relieved last month when a Post reporter told her about
                Cadenhead’s arrest.
            </p>
            <p>“I’m tired of living in fear,” she said.</p>
            <p>
                Her daughter, now 17, has been in and out of mental health
                institutions in the past few years, she said. She has found a
                measure of stability since undergoing trauma therapy for the
                online abuse, the mother said.
            </p>
            <p>
                But a reminder remains: a scar — the number 764 — is still
                visible on her thigh.
            </p>
        </div>
    </body>
        
</html>